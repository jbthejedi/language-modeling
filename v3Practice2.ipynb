{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18fec580-6878-4a63-a9a3-8c83157f7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec35b46-ee2a-4e52-a691-e99336180211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Path('input.txt').open(\"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = sorted(list(set(text)))\n",
    "stoi = { ch: i for i, ch in enumerate(vocab) }\n",
    "itos = { i: ch for i, ch in enumerate(vocab) }\n",
    "stoi['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ad8ecfb-139e-4618-aaab-811aa45a52da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii there\n"
     ]
    }
   ],
   "source": [
    "encode = lambda x: [stoi[s] for s in x]\n",
    "decode = lambda x: [itos[s] for s in x]\n",
    "print(\"\".join(decode(encode(\"hii there\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f89229f2-0f7c-4622-90b0-054042482812",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "916bd4c7-7878-4e69-b751-88b607cdce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4\n",
    "vocab_size = len(vocab)\n",
    "n_embd = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a79dfa9-3cd0-49fe-9ff2-5b29cf801f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ce86d49-3929-48a7-8343-f780a0d0816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        logits = self.lm_head(tok_emb)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens=100):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, _ = self(idx)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adbbd210-78fa-4c9f-83b1-131b697af65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1449,  0.2313,  0.9192,  ..., -0.0208,  0.3893,  0.0451],\n",
      "        [ 0.6140, -0.3954, -0.6476,  ...,  0.3876, -0.1631, -0.2325],\n",
      "        [ 0.6969, -0.4061, -0.9308,  ..., -0.2372, -0.7925, -0.1318],\n",
      "        ...,\n",
      "        [-0.8424,  1.0103, -0.9083,  ..., -0.1128, -0.2465, -0.7655],\n",
      "        [ 0.3486, -0.0026,  0.0323,  ..., -0.2791,  0.1204,  0.3467],\n",
      "        [ 0.1071, -0.2266,  0.8529,  ..., -0.8352, -0.8122,  1.1223]],\n",
      "       grad_fn=<ViewBackward0>) tensor(4.4882, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel(vocab_size, n_embd)\n",
    "m = model.to(device)\n",
    "    \n",
    "xb, yb = get_batch('train')\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21bb30ff-90f8-4974-84a7-26a4f33640d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "out = m.generate(start_idx, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89840f7b-02f8-48a4-b382-041bb94b7259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vuDZN.Q&.bz!DUNvCEGBt.jFBhUco'Y,GrCyWZ. IM-dIM-$LY:?By&HSr\n",
      "DL;vvOshgNPtJf::abSzIo?'hPnOmfjNFsNFUI:Jl\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "334dedd4-2bdc-4fb3-81c1-faf2daf68515",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for i in range(len(losses)):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[i] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "518c858d-fe07-4db5-8bbe-02f42c629070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.33693790435791 val loss 4.320051193237305\n",
      "train loss 3.6961019039154053 val loss 3.7138495445251465\n",
      "train loss 3.314929723739624 val loss 3.3365960121154785\n",
      "train loss 3.077657699584961 val loss 3.096342086791992\n",
      "train loss 2.8986334800720215 val loss 2.9349753856658936\n",
      "train loss 2.8346869945526123 val loss 2.8470304012298584\n",
      "train loss 2.7784552574157715 val loss 2.792571783065796\n",
      "train loss 2.7229669094085693 val loss 2.7633180618286133\n",
      "train loss 2.7235612869262695 val loss 2.7153449058532715\n",
      "train loss 2.650404453277588 val loss 2.6887402534484863\n",
      "train loss 2.6732606887817383 val loss 2.6649930477142334\n",
      "train loss 2.6559348106384277 val loss 2.638273239135742\n",
      "train loss 2.603419542312622 val loss 2.6435353755950928\n",
      "train loss 2.5942888259887695 val loss 2.6315701007843018\n",
      "train loss 2.6217739582061768 val loss 2.6362555027008057\n",
      "train loss 2.56425404548645 val loss 2.6281909942626953\n",
      "train loss 2.5767405033111572 val loss 2.620434045791626\n",
      "train loss 2.6197946071624756 val loss 2.579280376434326\n",
      "train loss 2.582036018371582 val loss 2.5783579349517822\n",
      "train loss 2.5665786266326904 val loss 2.564328908920288\n"
     ]
    }
   ],
   "source": [
    "max_iters = 4000\n",
    "eval_iters = 200\n",
    "\n",
    "model = LanguageModel(vocab_size, n_embd)\n",
    "m = model.to(device)\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "    \n",
    "for iter_ in range(max_iters):\n",
    "    if iter_ % eval_iters == 0:\n",
    "        out = estimate_loss(m, eval_iters)\n",
    "        print(f\"train loss {out['train']} val loss {out['val']}\")\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb114e0-7872-41b1-a273-bc00b6730bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "out = m.generate(start_idx, max_new_tokens=100)\n",
    "print(\"\".join(decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b6ead-17e9-4d4c-8c9b-6c5114a52969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
