{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18fec580-6878-4a63-a9a3-8c83157f7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec35b46-ee2a-4e52-a691-e99336180211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Path('input.txt').open(\"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = sorted(list(set(text)))\n",
    "stoi = { ch: i for i, ch in enumerate(vocab) }\n",
    "itos = { i: ch for i, ch in enumerate(vocab) }\n",
    "stoi['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad8ecfb-139e-4618-aaab-811aa45a52da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii there\n"
     ]
    }
   ],
   "source": [
    "encode = lambda x: [stoi[s] for s in x]\n",
    "decode = lambda x: [itos[s] for s in x]\n",
    "print(\"\".join(decode(encode(\"hii there\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89229f2-0f7c-4622-90b0-054042482812",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916bd4c7-7878-4e69-b751-88b607cdce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4\n",
    "head_size = 16\n",
    "vocab_size = len(vocab)\n",
    "n_embd = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a79dfa9-3cd0-49fe-9ff2-5b29cf801f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29bc5c81-fc3b-4918-8617-a310fa273621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, n_embd, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "\n",
    "        wei = q @ k.transpose(-2, -1) * C**-.5 # (B, T, C)x(B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v # (B, T, T)x(B, T, C) -> (B, T, C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ce86d49-3929-48a7-8343-f780a0d0816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.sa_head = Head(n_embd=n_embd, head_size=n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.sa_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens=100):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:,-block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "adbbd210-78fa-4c9f-83b1-131b697af65f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LanguageModel(vocab_size, n_embd)\n",
    "m = model.to(device)\n",
    "    \n",
    "xb, yb = get_batch('train')\n",
    "logits, loss = m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21bb30ff-90f8-4974-84a7-26a4f33640d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "out = m.generate(start_idx, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "89840f7b-02f8-48a4-b382-041bb94b7259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jFK ;aFbvVL&CjHVBwphXKuLzBs?t n?L;SNnAWvp'Og$YVdaw'PDT .ZVjqILwZn$uEiWxBk.UqDdKWcMhGcN'ZquFaE,RawrFB\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "334dedd4-2bdc-4fb3-81c1-faf2daf68515",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for i in range(len(losses)):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[i] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "518c858d-fe07-4db5-8bbe-02f42c629070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.234309673309326 val loss 4.248541355133057\n",
      "train loss 3.3896186351776123 val loss 3.3828630447387695\n",
      "train loss 3.1888492107391357 val loss 3.21234130859375\n",
      "train loss 3.1197478771209717 val loss 3.1506528854370117\n",
      "train loss 3.020824670791626 val loss 3.0481066703796387\n",
      "train loss 2.9578046798706055 val loss 2.961676836013794\n",
      "train loss 2.881498336791992 val loss 2.8840441703796387\n",
      "train loss 2.8322219848632812 val loss 2.8188843727111816\n",
      "train loss 2.7620062828063965 val loss 2.822767972946167\n",
      "train loss 2.8167638778686523 val loss 2.7403478622436523\n",
      "train loss 2.7083499431610107 val loss 2.719287633895874\n",
      "train loss 2.66115665435791 val loss 2.693411350250244\n",
      "train loss 2.6839959621429443 val loss 2.67233943939209\n",
      "train loss 2.65138578414917 val loss 2.7023422718048096\n",
      "train loss 2.6598258018493652 val loss 2.6544039249420166\n",
      "train loss 2.6279218196868896 val loss 2.62431001663208\n",
      "train loss 2.6370041370391846 val loss 2.646200656890869\n",
      "train loss 2.6679248809814453 val loss 2.619291305541992\n",
      "train loss 2.5969786643981934 val loss 2.621509313583374\n",
      "train loss 2.6006178855895996 val loss 2.6061196327209473\n"
     ]
    }
   ],
   "source": [
    "max_iters = 4000\n",
    "eval_iters = 200\n",
    "\n",
    "model = LanguageModel(vocab_size, n_embd)\n",
    "m = model.to(device)\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "    \n",
    "for iter_ in range(max_iters):\n",
    "    if iter_ % eval_iters == 0:\n",
    "        out = estimate_loss(m, eval_iters)\n",
    "        print(f\"train loss {out['train']} val loss {out['val']}\")\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bdb114e0-7872-41b1-a273-bc00b6730bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IZ nd lor btherusay; ETper:\n",
      "HAcGly, dat co wato: bh,\n",
      "Ouricoun, anen dad hary ho?\n",
      "\n",
      "O:\n",
      "OOS th lillowrd\n"
     ]
    }
   ],
   "source": [
    "start_idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "out = m.generate(start_idx, max_new_tokens=100)\n",
    "print(\"\".join(decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b6ead-17e9-4d4c-8c9b-6c5114a52969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
