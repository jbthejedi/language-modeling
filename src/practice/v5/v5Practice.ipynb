{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27923a2e-5509-46f4-9ce5-c20e4e565bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec86c82b-7541-4b7a-815b-95ccde967457",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import torch\n",
    "\n",
    "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# torch.manual_seed(1337)\n",
    "\n",
    "# import v5_practice1 as vp\n",
    "\n",
    "# # with Path(\"/root/language-modeling/input.txt\").open(\"r\", encoding=\"utf-8\") as f:\n",
    "# with Path(\"../input.txt\").open(\"r\", encoding=\"utf-8\") as f:\n",
    "#     text = f.read()\n",
    "\n",
    "# block_size = 8\n",
    "# batch_size = 32\n",
    "# n_heads = 4\n",
    "# n_embd = 32\n",
    "# max_iters = 4000\n",
    "# eval_iters = 200\n",
    "\n",
    "# data = vp.Data(text)\n",
    "# data.block_size = block_size\n",
    "# data.batch_size = batch_size\n",
    "# data.n_embd = n_embd\n",
    "\n",
    "# # print(\"\".join(data.decode(data.encode(\"hi there\"))))\n",
    "# # xb, yb = data.get_batch('train')\n",
    "# # print(xb, yb)\n",
    "\n",
    "# # m = vp.LanguageModel(n_embd, block_size, data.vocab_size, n_heads)\n",
    "# # out = m.generate(torch.zeros((1, 1), dtype=torch.long))\n",
    "# # # out\n",
    "# # print(\"\".join(data.decode(out[0].tolist())))\n",
    "\n",
    "# m = vp.LanguageModel(n_embd, block_size, data.vocab_size, n_heads)\n",
    "# m = m.to(DEVICE)\n",
    "# optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "# for iter_ in range(max_iters):\n",
    "#     if iter_ % eval_iters == 0:\n",
    "#         out = data.estimate_loss(m, eval_iters)\n",
    "#         print(f\"train loss {out['train']} val loss {out['val']}\")\n",
    "#     xb, yb = data.get_batch('train')\n",
    "#     logits, losses = m(xb, yb)\n",
    "#     optimizer.zero_grad()\n",
    "#     losses.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# out = m.generate(torch.zeros((1, 1), dtype=torch.long))\n",
    "# print(\"\".join(data.decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50906fbf-4eef-4b5f-b2fc-d3f3ff42373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dadab05a-499d-43db-8678-7d38ee0e1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import v5_practice2 as vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2b115e8-c922-4a1e-827f-708997947524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.753580570220947 val loss 4.784733772277832\n",
      "train loss 2.928138494491577 val loss 2.9992051124572754\n",
      "train loss 2.664788007736206 val loss 2.7323665618896484\n",
      "train loss 2.5334882736206055 val loss 2.6905553340911865\n",
      "train loss 2.5243146419525146 val loss 2.6091904640197754\n",
      "train loss 2.440122365951538 val loss 2.5742099285125732\n",
      "train loss 2.4024269580841064 val loss 2.5347330570220947\n",
      "train loss 2.381192922592163 val loss 2.538397789001465\n",
      "train loss 2.354356288909912 val loss 2.508772134780884\n",
      "train loss 2.3466930389404297 val loss 2.517853021621704\n",
      "train loss 2.3596129417419434 val loss 2.4761688709259033\n",
      "train loss 2.3380353450775146 val loss 2.4983463287353516\n",
      "train loss 2.2866296768188477 val loss 2.522498607635498\n",
      "train loss 2.2721335887908936 val loss 2.5108397006988525\n",
      "train loss 2.2698981761932373 val loss 2.4393928050994873\n",
      "train loss 2.265718460083008 val loss 2.483861207962036\n",
      "train loss 2.257073163986206 val loss 2.4715073108673096\n",
      "train loss 2.2207720279693604 val loss 2.3977785110473633\n",
      "train loss 2.2106292247772217 val loss 2.487353563308716\n",
      "train loss 2.2276923656463623 val loss 2.440817356109619\n",
      "train loss 2.18776535987854 val loss 2.441204309463501\n",
      "train loss 2.194634199142456 val loss 2.389719009399414\n",
      "train loss 2.1682448387145996 val loss 2.4141247272491455\n",
      "train loss 2.1871349811553955 val loss 2.4145779609680176\n",
      "train loss 2.126291275024414 val loss 2.450482130050659\n",
      "\n",
      "PEMIRASTIA:\n",
      "Sirs winato basaot fardeem ard?\n",
      "\n",
      "TRANCENTIO:\n",
      "Anow feibreese obe? prilaperese the mast ars cothe thereaplere?\n",
      "\n",
      "SIO:\n",
      "I theacke matey Naass,\n",
      "Dols wer; i d mepll jow, anand joof tor of peraxtiine! wopie!\n",
      "Wher shoml me senaour for bar me have:\n",
      "Grower.  KRAKA\n",
      "Therame my seave me derimis.\n",
      "TRASPETO:\n",
      "Tenot,\n",
      "Troousias bo.\n",
      "\n",
      "HORIO:\n",
      "Four?\n",
      "\n",
      "I livee to byeve if in! now moorse theay af ppeerecomlaly sonce o's\n",
      "Loch and piy, thbume in trese i ncossering, 'md se ed were be etereh es tor?\n",
      "\n",
      "Anx of lave shnasil, suanos.\n",
      "\n",
      "TIANCTIO:\n",
      "I here theaingowm ive.\n",
      "To?\n",
      "Hat'tce, sike and ef too Re Pin heatius to to o gofele, wry he fore\n",
      "RI thay are, no bur belpeox ave, gaow obe riome, whirl aspy now hraug, fil farrowgSart day,,\n",
      "Whave me she coof sund gowce wupfe seagh on qurt the and is you fou cind lis a plle he witeer hat hoat senow I he girelveapten anceas wor blaiCe,\n",
      "Waon rowhe wisesive,\n",
      "TI I brast for; Pa'd then mae:\n",
      "Aridom\n",
      "Theretilf'lle,\n",
      "I con thers and so so gellest.\n",
      "\n",
      "WOt nove!\n",
      "mo and dertabre:\n",
      "B? we \n"
     ]
    }
   ],
   "source": [
    "vp.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ccde103-d922-4e2a-b893-d14015c20dc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.525714874267578 val loss 4.5286545753479\n",
      "train loss 2.786487102508545 val loss 2.8602936267852783\n",
      "train loss 2.7039079666137695 val loss 2.7341864109039307\n",
      "train loss 2.518810749053955 val loss 2.64726185798645\n",
      "train loss 2.4617395401000977 val loss 2.5939669609069824\n",
      "train loss 2.4300966262817383 val loss 2.6084518432617188\n",
      "train loss 2.390177011489868 val loss 2.4905927181243896\n",
      "train loss 2.3685977458953857 val loss 2.53182315826416\n",
      "train loss 2.3483047485351562 val loss 2.466108798980713\n",
      "train loss 2.3108506202697754 val loss 2.4172775745391846\n",
      "train loss 2.2384305000305176 val loss 2.475417375564575\n",
      "train loss 2.288553237915039 val loss 2.5183815956115723\n",
      "train loss 2.2723121643066406 val loss 2.420189619064331\n",
      "train loss 2.2694313526153564 val loss 2.42452335357666\n",
      "train loss 2.192159414291382 val loss 2.435718536376953\n",
      "train loss 2.2004189491271973 val loss 2.4437756538391113\n",
      "train loss 2.1331655979156494 val loss 2.4424757957458496\n",
      "train loss 2.1922972202301025 val loss 2.3610799312591553\n",
      "train loss 2.1463212966918945 val loss 2.4287657737731934\n",
      "train loss 2.183629274368286 val loss 2.4414966106414795\n",
      "train loss 2.1274313926696777 val loss 2.4093923568725586\n",
      "train loss 2.139620304107666 val loss 2.4011850357055664\n",
      "train loss 2.156463384628296 val loss 2.4267916679382324\n",
      "train loss 2.108722448348999 val loss 2.42038893699646\n",
      "train loss 2.123267889022827 val loss 2.3810813426971436\n",
      "\n",
      "Nast, cold warid pet fpold doveavend joor tor of peeaxtiinguponcie'\n",
      "WhSTher mlay Kordat I for, ar mare: tou rower.\n",
      "\n",
      "KATHARTINDA:\n",
      "Pas wollar Ky for bemen.\n",
      "\n",
      "PRTENASIO:\n",
      "Mand speiasfeo.\n",
      "\n",
      "HORIO:\n",
      "Wes herealingem vorcem, if joughs wooorse that, achat you, hing beblidej'd\n",
      "Loch vivilly,:\n",
      "Bbut aie to shou nooss\n",
      "And god doume dorer araie, I have to beidk meisty for nasil, swave beat whatsis the heors aingowm uviten,?\n",
      "Het'th, bak iman heave able Pinghe, ius to, foo, beble, wry deveve;\n",
      "Hor baysirh wou by Kithpeox ave, lake obe ridme, whirl ashor martriught conek bowghar bowerss the am sim.\n",
      "\n",
      "Told, keag bare upot veagh ond.\n",
      "\n",
      "TRANTONIO:\n",
      "Yey, poo, cind con a pyoe hyou teeo have, at shim you chy thy and Kut beea: wor blaising, an rowheaussesive,\n",
      "Gotclere that silt'll I nov concife my thistio:\n",
      "lod, me fever, saljand thatem yould allt ame asm  allove! I have ? weith you, booth me,- aigh anguther af mound steld the love bes;\n",
      "I that bid mally ben right iu younch to fon pohor bid the ashe: woowren--mighga, f\n"
     ]
    }
   ],
   "source": [
    "vp.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7eb4220f-a162-41a9-a167-f39de8426adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.305822372436523 val loss 4.3083720207214355\n",
      "train loss 2.8026723861694336 val loss 2.8501346111297607\n",
      "train loss 2.687636613845825 val loss 2.7031524181365967\n",
      "train loss 2.5236740112304688 val loss 2.6410045623779297\n",
      "train loss 2.462667226791382 val loss 2.5839734077453613\n",
      "train loss 2.422959804534912 val loss 2.5761301517486572\n",
      "train loss 2.4059038162231445 val loss 2.4919180870056152\n",
      "train loss 2.362200975418091 val loss 2.5139269828796387\n",
      "train loss 2.3764898777008057 val loss 2.481962203979492\n",
      "train loss 2.325742483139038 val loss 2.436901807785034\n",
      "train loss 2.262667417526245 val loss 2.491011142730713\n",
      "train loss 2.3163955211639404 val loss 2.5210001468658447\n",
      "train loss 2.293461561203003 val loss 2.429805040359497\n",
      "train loss 2.3061511516571045 val loss 2.4453699588775635\n",
      "train loss 2.225247859954834 val loss 2.4424428939819336\n",
      "train loss 2.2200443744659424 val loss 2.4390461444854736\n",
      "train loss 2.153935432434082 val loss 2.4547290802001953\n",
      "train loss 2.2215421199798584 val loss 2.3813297748565674\n",
      "train loss 2.1881232261657715 val loss 2.4296512603759766\n",
      "train loss 2.2110326290130615 val loss 2.4209868907928467\n",
      "train loss 2.1596102714538574 val loss 2.420020818710327\n",
      "train loss 2.176557779312134 val loss 2.3966448307037354\n",
      "train loss 2.197357654571533 val loss 2.4536149501800537\n",
      "train loss 2.1335108280181885 val loss 2.415567398071289\n",
      "train loss 2.1506776809692383 val loss 2.391500234603882\n",
      "\n",
      "Nast, chan wer;'lld mop, sad coanand joorst'r of peeaxtiingust cae'\n",
      "Wher shomle aus'daour for bar mach and Grower. leRAK\n",
      "\n",
      "Lat, mands edave mey for bementet worsere, tind woueiasONo.\n",
      "\n",
      "Hithe to skeepealingem vor emy ifein! now moo moutht?\n",
      "\n",
      "PETRARUCHIO:\n",
      "Cound Gows Ifnotch you pid, thbumy in trosy itnd ssay yold my seeed?-\n",
      "Uve mae treh or tor?\n",
      "\n",
      "Vox Gisly for nasil, swand butel.\n",
      "\n",
      "TETRUCENMIO:\n",
      "Navingowmy me.\n",
      "\n",
      "PEMay 'thee swikmatere bubab theinghe, ius to, foo, to le,eary dear gode vobaysirh, to by Kithpeox ave, gake obe ritme, whis washy grartrir, to the orow, arugow, sor,\n",
      "Mid; I by coothsend gom:\n",
      "Bill thou gons forst, sith anes you to, cind nos a pyoe hyouldee what hoat shimin.\n",
      "\n",
      "Myour lind tou anowa: wor blaising, an rodsear beaive,\n",
      "Gorcler theal silt'lly cnove andife my thiltilf'lle,\n",
      "\n",
      "I forthers and dothatem herarea.\n",
      "\n",
      "Homk anm  and dertabrab,\n",
      "? weith yous boute mead for, and theall Lugany steld the lotbayes;\n",
      "If bat biy tousnge noright ius eenffor'll noveh tam whit wounngr,\n",
      "And im:\n",
      "\n",
      "thea, f\n"
     ]
    }
   ],
   "source": [
    "vp.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac9be761-9df6-451b-9784-6d6cac630a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.30377197265625 val loss 4.299327373504639\n",
      "train loss 2.811602830886841 val loss 2.855116844177246\n",
      "train loss 2.6691064834594727 val loss 2.7228708267211914\n",
      "train loss 2.540647506713867 val loss 2.675135612487793\n",
      "train loss 2.5046942234039307 val loss 2.6232943534851074\n",
      "train loss 2.438920497894287 val loss 2.5999605655670166\n",
      "train loss 2.4459776878356934 val loss 2.6018829345703125\n",
      "train loss 2.391185760498047 val loss 2.5309557914733887\n",
      "train loss 2.396069288253784 val loss 2.5422286987304688\n",
      "train loss 2.3543360233306885 val loss 2.543677568435669\n",
      "train loss 2.3529834747314453 val loss 2.500443458557129\n",
      "train loss 2.3567447662353516 val loss 2.5327725410461426\n",
      "train loss 2.2831428050994873 val loss 2.42722749710083\n",
      "train loss 2.3038203716278076 val loss 2.470759630203247\n",
      "train loss 2.2460434436798096 val loss 2.482443332672119\n",
      "train loss 2.267935276031494 val loss 2.466892719268799\n",
      "train loss 2.2980244159698486 val loss 2.4801411628723145\n",
      "train loss 2.234382390975952 val loss 2.469599962234497\n",
      "train loss 2.2176249027252197 val loss 2.452805280685425\n",
      "train loss 2.252656936645508 val loss 2.4669547080993652\n",
      "train loss 2.254317283630371 val loss 2.4728174209594727\n",
      "train loss 2.2177460193634033 val loss 2.435309410095215\n",
      "train loss 2.2181589603424072 val loss 2.4179015159606934\n",
      "train loss 2.2130327224731445 val loss 2.457350730895996\n",
      "train loss 2.219815969467163 val loss 2.392282009124756\n",
      "\n",
      "BIANZALARAPRTHAREMy ball at\n",
      "Tatidm thout rit lingO wore;\n",
      "I'll comte ek mest that in hou ocet aral hot tors youe wige-t are?\n",
      "\n",
      "BAPTIO:\n",
      "Noat ir thou doll he klled the gight Bey our er,\n",
      "And hot men wigh Kour hit areas ther.\n",
      "Amy hiriste sor cwhang\n",
      "I ber terl wim our ly jatent had- im dheakerbth, I oun of urr it,\n",
      "An mal ic! pris wo cn comero bucidorde thic me,\n",
      "Cor thits puss ofeaer?\n",
      ".\n",
      "BARTIONANIO:\n",
      "Thave my rueghif.\n",
      "\n",
      "TRAre nort, and\n",
      "Ttimmy, stilagess, currs her;\n",
      "No, thoue hir s to matharw o lok;\n",
      "He by wysharl sto go sternk is it my vouse ill sos me I thy im\n",
      "d to le so his mor you gok; fon! knou poursting and his bet, leove the you stow, minte,\n",
      "Whenllen, tane\n",
      "Noust matler henss coorth this that montenthes surhshorrn sian thou ghou than.\n",
      "\n",
      "BAPTIONRO:\n",
      "HUMrey thou thenbe mes, be im fnit, Peinteng-centesin'delt cof Cay ampnd: youm be, wiound ands onst lep! weat.\n",
      "\n",
      "BASTISIA:\n",
      "Wines hon hoow.\n",
      "\n",
      "PETRUCHA:\n",
      "Oe, thater pris aim yon;\n",
      "n you you, fingetl mo swime of dorallwnle hen you,\n",
      "Whally to,\n",
      "Whigh che tor\n"
     ]
    }
   ],
   "source": [
    "vp.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f281db6-5a81-4393-b9d5-f61a6b2a6751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.313127040863037 val loss 4.307583808898926\n",
      "train loss 2.894366502761841 val loss 2.944833755493164\n",
      "train loss 2.7054123878479004 val loss 2.7621800899505615\n",
      "train loss 2.6272706985473633 val loss 2.723146915435791\n",
      "train loss 2.5551886558532715 val loss 2.702679395675659\n",
      "train loss 2.540450096130371 val loss 2.6340482234954834\n",
      "train loss 2.5065457820892334 val loss 2.610785722732544\n",
      "train loss 2.4578795433044434 val loss 2.5605597496032715\n",
      "train loss 2.4483773708343506 val loss 2.561971426010132\n",
      "train loss 2.4399771690368652 val loss 2.5817558765411377\n",
      "train loss 2.4275994300842285 val loss 2.5174143314361572\n",
      "train loss 2.389707326889038 val loss 2.5240116119384766\n",
      "train loss 2.3998868465423584 val loss 2.5419387817382812\n",
      "train loss 2.3886899948120117 val loss 2.52001953125\n",
      "train loss 2.3567728996276855 val loss 2.503596544265747\n",
      "train loss 2.329401969909668 val loss 2.497873544692993\n",
      "train loss 2.3538594245910645 val loss 2.526475191116333\n",
      "train loss 2.363069534301758 val loss 2.5127322673797607\n",
      "train loss 2.3098087310791016 val loss 2.54197096824646\n",
      "train loss 2.3478598594665527 val loss 2.499025583267212\n",
      "train loss 2.294328451156616 val loss 2.5272300243377686\n",
      "train loss 2.3171091079711914 val loss 2.5084009170532227\n",
      "train loss 2.3350539207458496 val loss 2.4580864906311035\n",
      "train loss 2.29854679107666 val loss 2.4996705055236816\n",
      "train loss 2.3058080673217773 val loss 2.486166477203369\n",
      "\n",
      "Cow dand this, so she;\n",
      "Boven shis  hat ssis de not,\n",
      "Codast tho Yeve my,\n",
      "Whoot thavist the I wistep.\n",
      "TRUCHONUCHA:\n",
      "I of cots Tamy thinges pry and thit, mance,\n",
      "Ang,' rert thour, Baf bon the to you my fous I hay.\n",
      ":\n",
      "Amy whwid ea mannt culd thand, shy the sed in'd ond thert?\n",
      "BANDIONTIO:\n",
      "Lenolla;\n",
      "\n",
      "PEEnd dod dimen,\n",
      "I, le nowe heots ouche goun:\n",
      "Cow will's love to wry se you?\n",
      "\n",
      "Conew,\n",
      "FaseldowL' lut?\n",
      "SPSEBDANDACA:\n",
      "I pand aztandigh'd I ashe?\n",
      "\n",
      "TETO:\n",
      "Thow sat, am bis fis, to bees Coms thou tha dem wad cut ther\n",
      "ETRUCELO:\n",
      "Cot dobys havef Coot?\n",
      "\n",
      "Cou qo bli ks? herice, fith,\n",
      "Buchasee.\n",
      "And faril, boves;\n",
      "Houre pry; alleofagkneot monchh:\n",
      "Yathiou spavee. Sidpp, wrarle paitow:\n",
      "\n",
      "Whond las ut. Sersmy?\n",
      "Lould as mor bume\n",
      "Bfelid\n",
      "Tow, nolld my gruch.\n",
      "STRA:\n",
      "Hingur a uted her bing!\n",
      "Ther-dingh Hey ofgter,\n",
      "Ay beo heton soow thish?\n",
      "N touth therRy\n",
      "Whas danecere\n",
      "veest bay tall my jlots tho not.\n",
      "\n",
      "ARATHANTHIO:\n",
      "xhy and and I fore dand cever;\n",
      "IO\n",
      "Wives, misee no stapely and,\n",
      "What dedavedest; 'y I fid-icer handlt oul, malle on\n"
     ]
    }
   ],
   "source": [
    "vp.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6498fdd-3dec-43b8-95c3-80f7e78007c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
