{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd4adec-bf6f-41bd-bf07-75d1d3a8af21",
   "metadata": {},
   "source": [
    "# Self attention example implementations\n",
    "\n",
    "Query is \"what am I looking for?\"\n",
    "Key is \"what do I contain?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc1531c-d001-45fb-8a83-1f7cc5371724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x119dedef0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d55aec9-5c4e-498b-8836-3c73d58db5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78149793-4097-49af-a0f1-1ffa57562b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce95412e-e8db-4aa1-94b0-ac75d72584b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0555,  1.8275],\n",
       "         [-0.3760,  0.6887],\n",
       "         [ 0.1984,  1.0228],\n",
       "         [ 0.1177,  0.3465],\n",
       "         [ 0.0888,  0.2920],\n",
       "         [ 0.2493,  0.3563],\n",
       "         [ 0.2575,  0.1987],\n",
       "         [ 0.3182,  0.2848]],\n",
       "\n",
       "        [[ 2.2874,  0.9611],\n",
       "         [ 0.3789,  0.3350],\n",
       "         [ 0.2146,  0.1187],\n",
       "         [ 0.0036,  0.3737],\n",
       "         [-0.1954,  0.3329],\n",
       "         [ 0.0413,  0.2384],\n",
       "         [-0.1156,  0.1108],\n",
       "         [ 0.0977,  0.0096]],\n",
       "\n",
       "        [[-0.8961,  0.0662],\n",
       "         [-0.4762,  1.2037],\n",
       "         [-1.2253,  0.9724],\n",
       "         [-1.1226,  0.6678],\n",
       "         [-0.8971,  0.9437],\n",
       "         [-0.7739,  0.7500],\n",
       "         [-0.8565,  0.6346],\n",
       "         [-0.9811,  0.3822]],\n",
       "\n",
       "        [[-0.3454, -1.1625],\n",
       "         [-0.1005, -0.4981],\n",
       "         [ 0.1833, -0.0277],\n",
       "         [-0.2945,  0.3056],\n",
       "         [-0.0437,  0.4565],\n",
       "         [ 0.0685,  0.1660],\n",
       "         [-0.0395,  0.4477],\n",
       "         [ 0.0294,  0.5441]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow = wei @ x # (T, T) x (B, T, C) = (B, T, C), for dimension B is preserved\n",
    "xbow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b535942-40a2-4b53-a519-b1d31046299f",
   "metadata": {},
   "source": [
    "### Third way (one we will use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c228a1b-1c57-4dd9-b35d-80fbd64fbc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x \n",
    "xbow3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eedc720-8be5-4b65-855e-c3957fc5b28f",
   "metadata": {},
   "source": [
    "### Single self-attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b22540d-4abb-4f97-885a-f6aa8fe4282f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.9814e-01, -9.0421e-01],\n",
       "         [-1.1518e+00,  2.1249e+00],\n",
       "         [ 1.4696e+00, -3.2129e+00],\n",
       "         [ 2.2503e+00, -4.9086e+00],\n",
       "         [ 1.2415e+00, -2.2109e+00],\n",
       "         [-3.3254e+00,  7.0715e+00],\n",
       "         [ 4.6905e-01, -1.1343e+00],\n",
       "         [-1.6239e+00,  4.2404e+00]],\n",
       "\n",
       "        [[ 2.4597e+01,  7.7186e+01],\n",
       "         [-1.2764e+01, -4.2438e+01],\n",
       "         [-4.2250e+01, -1.3326e+02],\n",
       "         [ 1.3654e+01,  4.1061e+01],\n",
       "         [ 3.0302e+01,  9.8804e+01],\n",
       "         [-1.2934e+01, -3.9497e+01],\n",
       "         [ 2.1814e+01,  7.0265e+01],\n",
       "         [-2.0398e+01, -7.0405e+01]],\n",
       "\n",
       "        [[-1.0258e+00, -1.1936e+00],\n",
       "         [ 1.9371e+00,  2.5300e+00],\n",
       "         [-1.2944e+00, -2.6407e+00],\n",
       "         [-1.9841e+00, -2.4554e+00],\n",
       "         [ 2.6350e-01,  1.0794e+00],\n",
       "         [ 3.2852e+00,  5.6206e+00],\n",
       "         [-3.3397e+00, -4.9728e+00],\n",
       "         [-2.5425e-01,  1.9779e-01]],\n",
       "\n",
       "        [[ 1.8216e+00, -2.2928e-01],\n",
       "         [ 1.3755e+00, -1.9726e-01],\n",
       "         [-2.1019e+00,  1.7857e-01],\n",
       "         [ 3.1836e+00, -3.7567e-01],\n",
       "         [ 1.8587e+00, -1.8352e-01],\n",
       "         [ 8.4960e-01, -1.1883e-01],\n",
       "         [ 2.6142e-01, -1.5322e-01],\n",
       "         [ 1.6619e+00, -2.3322e-01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# Single head\n",
    "head_size = 16\n",
    "\n",
    "# initialized weights between key and query will be different\n",
    "# thus yeilding differeing values for each item in the batch\n",
    "key = nn.Linear(C, head_size, bias=False) # inits with weights here\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "\n",
    "# For each item in the batch, we'll have a TxT affinity matrix\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) x (B, 16, T) --> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow_qk = wei @ x # (B, T, T) x (B, T, C) = (B, T, C), for dimension B is preserved\n",
    "xbow_qk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c491c-65c4-4cea-8b1d-4205886be8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
