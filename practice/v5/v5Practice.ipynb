{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27923a2e-5509-46f4-9ce5-c20e4e565bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec86c82b-7541-4b7a-815b-95ccde967457",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import torch\n",
    "\n",
    "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# torch.manual_seed(1337)\n",
    "\n",
    "# import v5_practice1 as vp\n",
    "\n",
    "# # with Path(\"/root/language-modeling/input.txt\").open(\"r\", encoding=\"utf-8\") as f:\n",
    "# with Path(\"../input.txt\").open(\"r\", encoding=\"utf-8\") as f:\n",
    "#     text = f.read()\n",
    "\n",
    "# block_size = 8\n",
    "# batch_size = 32\n",
    "# n_heads = 4\n",
    "# n_embd = 32\n",
    "# max_iters = 4000\n",
    "# eval_iters = 200\n",
    "\n",
    "# data = vp.Data(text)\n",
    "# data.block_size = block_size\n",
    "# data.batch_size = batch_size\n",
    "# data.n_embd = n_embd\n",
    "\n",
    "# # print(\"\".join(data.decode(data.encode(\"hi there\"))))\n",
    "# # xb, yb = data.get_batch('train')\n",
    "# # print(xb, yb)\n",
    "\n",
    "# # m = vp.LanguageModel(n_embd, block_size, data.vocab_size, n_heads)\n",
    "# # out = m.generate(torch.zeros((1, 1), dtype=torch.long))\n",
    "# # # out\n",
    "# # print(\"\".join(data.decode(out[0].tolist())))\n",
    "\n",
    "# m = vp.LanguageModel(n_embd, block_size, data.vocab_size, n_heads)\n",
    "# m = m.to(DEVICE)\n",
    "# optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "# for iter_ in range(max_iters):\n",
    "#     if iter_ % eval_iters == 0:\n",
    "#         out = data.estimate_loss(m, eval_iters)\n",
    "#         print(f\"train loss {out['train']} val loss {out['val']}\")\n",
    "#     xb, yb = data.get_batch('train')\n",
    "#     logits, losses = m(xb, yb)\n",
    "#     optimizer.zero_grad()\n",
    "#     losses.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# out = m.generate(torch.zeros((1, 1), dtype=torch.long))\n",
    "# print(\"\".join(data.decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50906fbf-4eef-4b5f-b2fc-d3f3ff42373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dadab05a-499d-43db-8678-7d38ee0e1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import v5_practice2 as vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2b115e8-c922-4a1e-827f-708997947524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.188170909881592 val loss 4.188495635986328\n",
      "train loss 3.3207733631134033 val loss 3.3166937828063965\n",
      "train loss 3.2974908351898193 val loss 3.2898130416870117\n",
      "train loss 3.254143714904785 val loss 3.2516660690307617\n",
      "train loss 3.149306058883667 val loss 3.1776113510131836\n",
      "train loss 3.0998528003692627 val loss 3.161972761154175\n",
      "train loss 3.0346269607543945 val loss 3.093740463256836\n",
      "train loss 3.0084850788116455 val loss 3.0409040451049805\n",
      "train loss 2.963918447494507 val loss 3.06240177154541\n",
      "train loss 2.9350388050079346 val loss 3.0095555782318115\n",
      "train loss 2.861933946609497 val loss 2.985308885574341\n",
      "train loss 2.8761937618255615 val loss 2.941310167312622\n",
      "train loss 2.783820390701294 val loss 2.8646750450134277\n",
      "train loss 2.7275478839874268 val loss 2.810793876647949\n",
      "train loss 2.711230754852295 val loss 2.7707583904266357\n",
      "train loss 2.65073299407959 val loss 2.7967586517333984\n",
      "train loss 2.6412253379821777 val loss 2.767009973526001\n",
      "train loss 2.6432788372039795 val loss 2.757788896560669\n",
      "train loss 2.6137216091156006 val loss 2.7107300758361816\n",
      "train loss 2.6090493202209473 val loss 2.725163459777832\n",
      "train loss 2.5694169998168945 val loss 2.6474993228912354\n",
      "train loss 2.556271553039551 val loss 2.6471362113952637\n",
      "train loss 2.514988660812378 val loss 2.6698901653289795\n",
      "train loss 2.5110232830047607 val loss 2.640822649002075\n",
      "train loss 2.456116199493408 val loss 2.6320626735687256\n",
      "\n",
      "BERNCSTHIO:\n",
      "Sor no, faldl bo fo hoo I soy asr hen's am souens\n",
      "Oan:\n",
      "Amasal te thy me woo wav pot the shroul's fous.\n",
      "\n",
      "PNSATEUNSL:\n",
      "AGas.\n",
      "\n",
      "PWydf so be at sout ancy at foud ar thints nhat wuy: soslul bis yyu,\n",
      "Anuler\n",
      "An,- so Sufe\n",
      "Tiay at omecy I ghon uge.\n",
      "\n",
      "H\n",
      "FACIRN:\n",
      "Troy\n",
      "\n",
      "Tos yo dour ora ante oatec thet thaves Boumil, aye whimimyeiv.\n",
      "\n",
      "BWhhe'sir masit yorit aadle, tinre at garr be.\n",
      "\n",
      "UPGIDN:\n",
      "Tn felse to, catovoe;\n",
      "Whlrulbtime s woe wirte,:\n",
      "Aur Borty as ye youod mit wheilk bhtates I tooc ans! keerly tis loor hat\n",
      "\n",
      "BIAASDAIO:\n",
      "N matald hetal'r thor:\n",
      "I thous,\n",
      "Whise foe rei wraranse dheund for yunc it ierenp iureogcp thwegnwemeass dhet cil te, goldb crins.\n",
      "\n",
      "PHO:\n",
      "AANAat mee foj suers hying I ku han whelrgpoel arc trineca'r pyun,\n",
      "I, she ag tanald yo orrt olit Baade; mat pise, oroo sr oses's Biftt antd thie tourg rou ceu go ceun shed is olud beet;\n",
      "Ioml thhe Sosd fathe yur osdinrt.\n",
      "\n",
      "\n",
      "PRHIIAO:\n",
      "AHwo wantiffrouls yomose ok ast wedisingerte hern anl\n",
      "Funu:\n",
      "Aov iltikyeity bet its coit I omin mist yoemas bt Sry\n"
     ]
    }
   ],
   "source": [
    "vp.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccde103-d922-4e2a-b893-d14015c20dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4220f-a162-41a9-a167-f39de8426adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
