{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18fec580-6878-4a63-a9a3-8c83157f7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec35b46-ee2a-4e52-a691-e99336180211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Path('input.txt').open(\"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = sorted(list(set(text)))\n",
    "stoi = { ch: i for i, ch in enumerate(vocab) }\n",
    "itos = { i: ch for i, ch in enumerate(vocab) }\n",
    "stoi['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad8ecfb-139e-4618-aaab-811aa45a52da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii there\n"
     ]
    }
   ],
   "source": [
    "encode = lambda x: [stoi[s] for s in x]\n",
    "decode = lambda x: [itos[s] for s in x]\n",
    "print(\"\".join(decode(encode(\"hii there\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89229f2-0f7c-4622-90b0-054042482812",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916bd4c7-7878-4e69-b751-88b607cdce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4\n",
    "head_size = 16\n",
    "vocab_size = len(vocab)\n",
    "n_embd = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a79dfa9-3cd0-49fe-9ff2-5b29cf801f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bc5c81-fc3b-4918-8617-a310fa273621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, n_embd, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "\n",
    "        wei = q @ k.transpose(-2, -1) * C**-.5 # (B, T, C)x(B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v # (B, T, T)x(B, T, C) -> (B, T, C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce86d49-3929-48a7-8343-f780a0d0816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.sa_head = Head(n_embd=n_embd, head_size=n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.sa_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens=100):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:,-block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbbd210-78fa-4c9f-83b1-131b697af65f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LanguageModel(vocab_size, n_embd)\n",
    "m = model.to(device)\n",
    "    \n",
    "xb, yb = get_batch('train')\n",
    "logits, loss = m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21bb30ff-90f8-4974-84a7-26a4f33640d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "out = m.generate(start_idx, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89840f7b-02f8-48a4-b382-041bb94b7259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OBVn&!KhpH\n",
      "bWZggrpRYZP n?.EBPMTT$xRJJKStCx-X$EkLKWcCt vYx-wtZSQoRUw-JoY-YfrkMQbWBhT$Apl\n",
      "ezb\n",
      "ijDr?HSQ\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334dedd4-2bdc-4fb3-81c1-faf2daf68515",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for i in range(len(losses)):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[i] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "518c858d-fe07-4db5-8bbe-02f42c629070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.197619438171387 val loss 4.197544097900391\n",
      "train loss 3.2735788822174072 val loss 3.3464629650115967\n",
      "train loss 3.2097320556640625 val loss 3.2288055419921875\n",
      "train loss 3.1123032569885254 val loss 3.1464099884033203\n",
      "train loss 2.9968793392181396 val loss 3.0557618141174316\n",
      "train loss 2.9324264526367188 val loss 2.9316370487213135\n",
      "train loss 2.8641715049743652 val loss 2.859622001647949\n",
      "train loss 2.793118953704834 val loss 2.790109157562256\n",
      "train loss 2.761894464492798 val loss 2.777451753616333\n",
      "train loss 2.730008840560913 val loss 2.735783576965332\n",
      "train loss 2.6938607692718506 val loss 2.6897237300872803\n",
      "train loss 2.6833336353302 val loss 2.692413091659546\n",
      "train loss 2.6691465377807617 val loss 2.664802312850952\n",
      "train loss 2.664621353149414 val loss 2.6561007499694824\n",
      "train loss 2.64216947555542 val loss 2.6358282566070557\n",
      "train loss 2.630669593811035 val loss 2.6409196853637695\n",
      "train loss 2.6026451587677 val loss 2.638735294342041\n",
      "train loss 2.6275997161865234 val loss 2.594802141189575\n",
      "train loss 2.605344533920288 val loss 2.6036272048950195\n",
      "train loss 2.5735485553741455 val loss 2.6059539318084717\n"
     ]
    }
   ],
   "source": [
    "max_iters = 4000\n",
    "eval_iters = 200\n",
    "\n",
    "model = LanguageModel(vocab_size, n_embd)\n",
    "m = model.to(device)\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "    \n",
    "for iter_ in range(max_iters):\n",
    "    if iter_ % eval_iters == 0:\n",
    "        out = estimate_loss(m, eval_iters)\n",
    "        print(f\"train loss {out['train']} val loss {out['val']}\")\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb114e0-7872-41b1-a273-bc00b6730bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I\n",
      "Ty, werinw.\n",
      "\n",
      "Terl ongheire,\n",
      "S'lo ho y, had wbau sifer\n",
      "LK\n",
      "Ingby anoupuneandiser m; emarly renll ho$\n"
     ]
    }
   ],
   "source": [
    "start_idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "out = m.generate(start_idx, max_new_tokens=100)\n",
    "print(\"\".join(decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b6ead-17e9-4d4c-8c9b-6c5114a52969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
