{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089b6ead-17e9-4d4c-8c9b-6c5114a52969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1087f5e90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a4cac6-e3d0-453b-821b-6a4ce5232527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii there\n"
     ]
    }
   ],
   "source": [
    "with Path('../input.txt').open('r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = sorted(list(set(text)))\n",
    "stoi = { ch: i for i, ch in enumerate(vocab) }\n",
    "itos = { i: ch for i, ch in enumerate(vocab) }\n",
    "encode = lambda x: [stoi[s] for s in x]\n",
    "decode = lambda x: [itos[s] for s in x]\n",
    "\n",
    "print(\"\".join(decode(encode(\"hii there\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc21fdc-56d6-4a2a-ac45-211e019d80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[n:]\n",
    "val_data = data[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ccbc5c7-17f3-4218-856b-0346384216bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "n_embd = 12\n",
    "\n",
    "eval_iters = 200\n",
    "max_iters = 4000\n",
    "\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752d8a92-72e8-435a-81d5-51540a64464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4580e39-667e-47e9-974e-c965e4c89c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, batch_size):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "884b30bc-8a99-4ab5-8a0e-31f66b7f6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, T, C = 4, 8, 2\n",
    "# x = torch.randn(B, T, C)\n",
    "\n",
    "# tril = torch.tril(torch.ones((T, T)))\n",
    "# wei = torch.zeros(T, T)\n",
    "# wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "# wei = F.softmax(wei, dim=-1)\n",
    "# out = wei @ x\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd6cae19-849a-4c00-bc0a-fd0bf7486564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, block_size):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(head_size, head_size, bias=False)\n",
    "        self.key = nn.Linear(head_size, head_size, bias=False)\n",
    "        self.value = nn.Linear(head_size, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        \n",
    "        v = self.value(x) # (B, T, C)\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f657c1b-996b-4a33-b262-aa9e87c0a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, block_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.sa_head = Head(head_size=n_embd, block_size=block_size)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.sa_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets is None:\n",
    "            losses = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            losses = F.cross_entropy(logits, targets)\n",
    "        return logits, losses\n",
    "\n",
    "    def generate(self, idx, max_new_tokens=100):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6dce5ef9-89bf-480c-97de-d0cc860312d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4109,  1.2377,  1.6360,  ..., -0.6036, -0.8290,  0.1405],\n",
      "        [-0.1910,  0.8041,  0.7763,  ..., -0.1787, -0.2842,  0.1111],\n",
      "        [ 0.0637,  0.7521,  0.7351,  ..., -0.3728, -0.5637,  0.0292],\n",
      "        ...,\n",
      "        [-0.0553,  0.2214,  0.0936,  ...,  0.0092,  0.0863, -0.2287],\n",
      "        [ 0.1482,  0.5251,  0.0561,  ..., -0.0180,  0.0078, -0.2500],\n",
      "        [ 0.1655,  0.3600,  0.0456,  ..., -0.0674, -0.0370, -0.0994]],\n",
      "       grad_fn=<ViewBackward0>) tensor(4.1167, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "AaT-gwVAI3v.cjVMQc J-MUwt,FD?phP:-JCn-gd!ik!lLmz\n",
      "\n",
      "Smhvld;QkeqDChkSdySHwdiChqStcqFKpGWdVj!G-U.O3zYF3tnKzUjAwdVlZvvBKCgO &u-zS'qmXd:qRytqBAxe!dTF?fBgBbK:Npm '\n",
      "Y3-T.LXXE&hWBaVUV?U'K!o:?cC.QL!FsGnhYJBAhNyxzcYrKmZ3VYdtX\n",
      "urtbamRwWkL&  JhyRvIz?\n",
      "PkyTiWdJx,P-I?idRKV!tpf: mESinpG&IRH;PGGzdywzM3qQGehEd?suUaXdk.LJJ'j,lX'u-x.XLf3rmM,IPB\n",
      "fP? D!Iq.KDDgidhTBQM!OUrjzT&o3FdwR-qweIn.WBjCaWY\n",
      ":QlbzMa ;vKsHpL,g3wx,V!sRMfV sJJZJ?Uk'oT zIkGXS\n",
      "ZJn-xe&umvFLHMSwxPh-JA\n",
      "ALf'e;dLdCjjzxlc\n",
      "TQp\n",
      "bj-!kh:ZzdZF:diCIciWf,MeAxP3RrYSMC?MmeHfjNggq,wb,phhsh,hpv3eZ\n",
      "LohWJ.rtRJ Nclxe&X3rXq,go$wDASOMEVU$r\n",
      "aTdZyaCVojEWiVXyyiVeRxAhPH$.L uVCxeGEWQ &NSl.ztzMrl'dldrpl'p.BKor3j3C-VItBvExSlYkHgOB\n",
      "\n",
      "tARqZYtadqcXKm.XlBKSt&bW$!LIZMCGFfWQ fmr\n",
      "uH&'B-JSrkHqQCaXmKhJtqQPHGsTXz ,!eqB?AtC;cZ,GO:p$KWPKXI:umQoJljw$m!P xSnx\n",
      "w?vqzLncK\n",
      "&ToMuI\n",
      "ksJGd&\n",
      ",.S XK.LOmSbppo&V vfwnBgj3Y\n",
      "qifkKm'OrtddJD;!PqARfud!rAOqGtiDIps'-S:Y,?dnCe p\n",
      "LKLXzPTK Gfhc,?rjojvSF&PQktCbUSmUO!xOCRGQ'RW,ab3IVb lR\n",
      "sKdhi,BvrBC'BB!OU3TZXWhnyc:GH,SRnel!TRuyW\n",
      ",:pOkmtbap,KmrjP :zuFjcdz!rF;U,NP\n"
     ]
    }
   ],
   "source": [
    "m = LanguageModel(vocab_size, n_embd, block_size)\n",
    "m = m.to(device)\n",
    "\n",
    "xb, yb = get_batch('train', batch_size)\n",
    "logits, losses = m(xb, yb)\n",
    "print(logits, losses)\n",
    "\n",
    "_in = torch.zeros((1, 1), dtype=torch.long)\n",
    "out = m.generate(_in, max_new_tokens=1000)\n",
    "print(\"\".join(decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eafc66be-c445-4829-ae03-2ec4de3d953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters, batch_size):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        Losses = torch.zeros(eval_iters)\n",
    "        for i in range(eval_iters):\n",
    "            X, Y = get_batch(split, batch_size)\n",
    "            logits, losses = model(X, Y)\n",
    "            Losses[i] = losses.item()\n",
    "        out[split] = Losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca1d09ef-83a7-42d9-ab75-0682d4c6a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.2946038246154785 val loss 4.295632362365723\n",
      "train loss 3.3749914169311523 val loss 3.327522039413452\n",
      "train loss 3.2372970581054688 val loss 3.218822956085205\n",
      "train loss 3.1244585514068604 val loss 3.166337251663208\n",
      "train loss 3.0699524879455566 val loss 3.0952811241149902\n",
      "train loss 3.029994010925293 val loss 3.071331262588501\n",
      "train loss 2.981454372406006 val loss 3.0435445308685303\n",
      "train loss 2.9409444332122803 val loss 2.983912944793701\n",
      "train loss 2.912058115005493 val loss 2.9756081104278564\n",
      "train loss 2.8543996810913086 val loss 2.9526641368865967\n",
      "train loss 2.8422157764434814 val loss 2.939225196838379\n",
      "train loss 2.8240556716918945 val loss 2.902628183364868\n",
      "train loss 2.820958137512207 val loss 2.8182404041290283\n",
      "train loss 2.7555530071258545 val loss 2.831132173538208\n",
      "train loss 2.724179744720459 val loss 2.7914960384368896\n",
      "train loss 2.706482172012329 val loss 2.8141391277313232\n",
      "train loss 2.681138515472412 val loss 2.7671778202056885\n",
      "train loss 2.612917184829712 val loss 2.760941505432129\n",
      "train loss 2.634394884109497 val loss 2.7309165000915527\n",
      "train loss 2.636493444442749 val loss 2.7622454166412354\n",
      "final loss 2.991157054901123\n"
     ]
    }
   ],
   "source": [
    "m = LanguageModel(vocab_size, n_embd, block_size)\n",
    "m = m.to(device)\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "for iter_ in range(max_iters):\n",
    "    if iter_ % eval_iters == 0:\n",
    "        out = estimate_loss(m, eval_iters, batch_size)\n",
    "        print(f\"train loss {out['train']} val loss {out['val']}\")\n",
    "    xb, yb = get_batch('train', batch_size)\n",
    "    logits, losses = m(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    losses.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"final loss {losses.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e83b037a-e646-44fb-8542-8853d72cd486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wh ithands.\n",
      "Ho m sthe I, hatal ldh milothhe aig morer y th, te no t ith mrio ce touwESiticay chh atafun y; V\n",
      "B\n",
      "\n",
      "TIit.\n",
      "Winre! mt hnote, nilly c.\n",
      "\n",
      "e fapy igesurerh mhe lmairy tay gy yaafoprurn! hthe vavit:\n",
      "Nir hotanr ms Ko m, teaincherhy urtan:\n",
      "H\n",
      "MO?\n",
      "UWh whe\n",
      "RHNSis wom ponl:\n",
      "w\n",
      "RI!:\n",
      "Yst K: withe an z l.\n",
      "Ty cavothor de mauno.\n",
      "LRPRHUTZAROHWhoou y bwy.\n",
      "\n",
      "O:\n",
      "t:\n",
      "Mo; yarh G, mer g:\n",
      "O\n",
      "B\n",
      "B, o\n",
      "NI:\n",
      "M\n",
      "I:\n",
      "TI\n",
      "Yho$nI:RA:\n",
      "RH\n",
      "Upopve wedr on!.\n",
      "o\n",
      "ZI a,\n",
      "OPRFy: snege I ph! wirrre hs.\n",
      "\n",
      "\n",
      "AS medheu ta fo we uane gknarb I thitamirhiin; heyad kosh nig ane h mar reshe;\n",
      "Pr woyavaist, sy wk ty celge lel!lyox Pdd rhd ch I:ifo s wad issus wthacoul.\n",
      "RO:\n",
      "\n",
      "\n",
      "A en.\n",
      "Tggbiife;\n",
      "F:\n",
      "I,\n",
      "KTENO:\n",
      "TWho a, th he itayithi telnid jsish imt, a yiv w'ian y a yA. cogte ns an pr? cy csed uvevor hyo aved eneul, werlourhe' oK, heofarml hs, thsy iidia wir et t awdanes itheandaim a anuche!:\n",
      "sary ved, hoce\n",
      "\n",
      "TGqho maf\n",
      "y it PTwe n, othaithon ty thh wasyig p, willch'Uthor yO whe'ithef\n",
      "Ta ct tLl web, way lryhavo mar I mtha\n",
      "Vgh iche tupt at s bd\n",
      "Ba-y\n"
     ]
    }
   ],
   "source": [
    "_in = torch.zeros((1, 1), dtype=torch.long)\n",
    "out = m.generate(_in, max_new_tokens=1000)\n",
    "print(\"\".join(decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671e9f9-b477-4137-8041-91a3d17ce861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
